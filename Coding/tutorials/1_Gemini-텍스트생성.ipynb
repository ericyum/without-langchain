{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d66591",
   "metadata": {},
   "source": [
    "참고 링크1 : https://ai.google.dev/gemini-api/docs/models?hl=ko <br>\n",
    "참고 링크2 : https://googleapis.github.io/python-genai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b1271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.10.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.40.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd57db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5839c8",
   "metadata": {},
   "source": [
    "### 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79213a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86407293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyDgCWDdLjZZ14PtRyk6Mag8l2p3ig0cS8E'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d87e7",
   "metadata": {},
   "source": [
    "**genai.Client** : https://googleapis.github.io/python-genai/genai.html#module-genai.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4594bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "VERTEXAI = True\n",
    "\n",
    "if VERTEXAI:\n",
    "    model_name = \"gemini-2.5-flash\"\n",
    "    project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "    location = \"us-central1\"  # or your preferred location\n",
    "else:\n",
    "    model_name = \"models/gemini-2.5-flash\"\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094be557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 **서울**입니다.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# 클라이언트 인스턴스 생성\n",
    "if VERTEXAI:\n",
    "    client = genai.Client(vertexai=True, project=project_id, location=location)\n",
    "else:\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "# 모델을 지정하고 컨텐츠의 답변을 요청\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=\"대한민국의 수도는 어디인가요?\",\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d17c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text='대한민국의 수도는 **서울**입니다.'\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='NW2ZaMG4ON2Cz7IP24Kz0Q4',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=10,\n",
       "    prompt_token_count=10,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=10\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=31,\n",
       "    total_token_count=51\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c4f72",
   "metadata": {},
   "source": [
    "### 시스템 안내 및 기타 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864c6e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Candidate(\n",
       "  content=Content(\n",
       "    parts=[\n",
       "      Part(\n",
       "        text='대한민국의 수도는 **서울**입니다.'\n",
       "      ),\n",
       "    ],\n",
       "    role='model'\n",
       "  ),\n",
       "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "  index=0\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb7f55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Content(\n",
       "  parts=[\n",
       "    Part(\n",
       "      text='대한민국의 수도는 **서울**입니다.'\n",
       "    ),\n",
       "  ],\n",
       "  role='model'\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04735fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Part(\n",
       "   text='대한민국의 수도는 **서울**입니다.'\n",
       " )]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccab719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 **서울**입니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd10c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 **서울**입니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776dd86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=10,\n",
       "  prompt_token_count=10,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=10\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=31,\n",
       "  total_token_count=51\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05119ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata.prompt_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8677578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModalityTokenCount(\n",
       "  modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "  token_count=10\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata.prompt_tokens_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5a6dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "31\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# 토큰 사용량 정보 출력\n",
    "\n",
    "# query 토큰 수\n",
    "print(response.usage_metadata.prompt_token_count)\n",
    "\n",
    "# throughts 토큰 수(생각하는 토큰 수)\n",
    "print(response.usage_metadata.thoughts_token_count)\n",
    "\n",
    "# query 토근수 + throughts 토큰 수 + 응답 토근 수\n",
    "print(response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7854b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "야옹! (하품하며 기지개를 쭉 편다) 음냐... 잘 왔냥? 😽\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Google Gemini 모델과 직접 상호작용하여 콘텐츠를 생성하는 데 사용되는 핵심 함수\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        # 시스템 인스트럭션\n",
    "        system_instruction=\"당신은 고양이이고, 이름은 야옹이입니다.\"\n",
    "    ),\n",
    "    contents=\"안녕\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9d8b6",
   "metadata": {},
   "source": [
    "### GenerateContentConfig : temperature 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc6ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, isn't a single magical entity, but rather a broad field of computer science focused on creating machines that can perform tasks that typically require human intelligence.\n",
      "\n",
      "At its core, AI works by **learning from data** to identify patterns, make predictions, or take actions, often without being explicitly programmed for every single scenario.\n",
      "\n",
      "Let's break down the fundamental concepts:\n",
      "\n",
      "---\n",
      "\n",
      "### The Core Idea: Learning from Data\n",
      "\n",
      "Imagine you want to teach a child to recognize a cat. You wouldn't give them a list of rules like \"if it has pointy ears AND whiskers AND meows, it's a cat.\" Instead, you'd show them many pictures of cats, point to real cats, and say \"That's a cat.\" You'd also show them pictures of dogs, birds, and other animals, saying \"That's *not* a cat.\" Over time, the child learns to identify cats on their own.\n",
      "\n",
      "AI works in a very similar way:\n",
      "\n",
      "1.  **Data is the Fuel:** AI systems are fed vast amounts of data (images, text, numbers, sounds, etc.). This data is often \"labeled\" (e.g., an image of a cat is tagged \"cat\").\n",
      "2.  **Algorithms are the Learning Rules:** These are the mathematical procedures or \"recipes\" that the AI uses to process the data and find patterns.\n",
      "3.  **Models are the Learned Knowledge:** As the algorithm processes the data, it builds an internal representation of the patterns it has found. This \"learned knowledge\" is called a model. It's like the child's internal understanding of what a cat looks like.\n",
      "\n",
      "---\n",
      "\n",
      "### How AI \"Learns\" (The Training Process)\n",
      "\n",
      "Let's use the example of teaching an AI to detect spam emails:\n",
      "\n",
      "1.  **Data Collection & Preparation:** You gather millions of emails, some marked \"spam\" and some \"not spam.\" This is your **training data**. The emails are converted into a format the computer can understand (e.g., counting specific words, identifying sender patterns).\n",
      "2.  **Choosing an Algorithm:** You select an appropriate machine learning algorithm (e.g., a Naive Bayes classifier, a Support Vector Machine, or a neural network).\n",
      "3.  **Training:**\n",
      "    *   The algorithm is fed the training data.\n",
      "    *   It analyzes the features of each email (words, sender, subject line, etc.) and tries to correlate them with the \"spam\" or \"not spam\" label.\n",
      "    *   Initially, it makes many mistakes.\n",
      "    *   For each mistake, it adjusts its internal parameters (like weights in a neural network) to reduce the error. This process is called **optimization**.\n",
      "    *   This iterative process continues until the model's predictions are consistently accurate on the training data.\n",
      "4.  **Evaluation:** You test the trained model on a separate set of emails it has never seen before (the **test data**). This tells you how well it generalizes to new, real-world scenarios.\n",
      "\n",
      "---\n",
      "\n",
      "### How AI \"Thinks\" (Making Predictions/Inference)\n",
      "\n",
      "Once the AI model is trained and evaluated, it's ready to be deployed. When a new, unseen email arrives:\n",
      "\n",
      "1.  The email's features are extracted in the same way as during training.\n",
      "2.  These features are fed into the trained model.\n",
      "3.  The model applies its learned patterns and outputs a prediction (e.g., \"This is 98% likely to be spam\").\n",
      "\n",
      "---\n",
      "\n",
      "### Key Branches of AI\n",
      "\n",
      "While \"AI\" is the umbrella term, most of what we call AI today falls under **Machine Learning (ML)**, and a powerful subset of ML is **Deep Learning (DL)**.\n",
      "\n",
      "1.  **Machine Learning (ML):**\n",
      "    *   **Supervised Learning:** The most common type. The AI learns from labeled data (input-output pairs).\n",
      "        *   **Classification:** Predicting a category (e.g., spam/not spam, cat/dog, disease/no disease).\n",
      "        *   **Regression:** Predicting a continuous value (e.g., house prices, temperature, stock prices).\n",
      "    *   **Unsupervised Learning:** The AI learns from unlabeled data, finding hidden patterns or structures on its own.\n",
      "        *   **Clustering:** Grouping similar data points together (e.g., customer segmentation, news topic discovery).\n",
      "        *   **Dimensionality Reduction:** Simplifying data while retaining important information.\n",
      "    *   **Reinforcement Learning:** The AI learns by trial and error, interacting with an environment and receiving rewards or penalties for its actions. This is how AI learns to play complex games (like AlphaGo) or control robots.\n",
      "\n",
      "2.  **Deep Learning (DL):**\n",
      "    *   A subset of Machine Learning that uses **Artificial Neural Networks (ANNs)** with many \"layers\" (hence \"deep\").\n",
      "    *   Inspired by the structure of the human brain, these networks consist of interconnected \"neurons\" that process information.\n",
      "    *   Deep learning excels at tasks involving complex, unstructured data like images, audio, and natural language.\n",
      "    *   **Convolutional Neural Networks (CNNs):** Great for image recognition and computer vision.\n",
      "    *   **Recurrent Neural Networks (RNNs) & Transformers:** Excellent for processing sequential data like text and speech (e.g., ChatGPT, Google Translate).\n",
      "\n",
      "---\n",
      "\n",
      "### What AI Needs to Work\n",
      "\n",
      "*   **Vast Amounts of Data:** The more high-quality, relevant data, the better.\n",
      "*   **Powerful Algorithms:** The mathematical recipes that enable learning.\n",
      "*   **Computational Power:** Training complex AI models requires significant processing power, often using specialized hardware like GPUs (Graphics Processing Units).\n",
      "*   **Human Expertise:** Data scientists, machine learning engineers, and domain experts are crucial for designing, training, and deploying AI systems, as well as interpreting their results and addressing biases.\n",
      "\n",
      "---\n",
      "\n",
      "### In Summary\n",
      "\n",
      "AI works by enabling machines to **learn from data** using **algorithms** to build **models** that can then **make predictions or decisions** on new, unseen data. It's not magic, but a sophisticated application of statistics, mathematics, and computer science that allows computers to mimic and even surpass certain aspects of human intelligence in specific tasks.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"Explain how AI works\"],\n",
    "    config=types.GenerateContentConfig(temperature=0.1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8bd47",
   "metadata": {},
   "source": [
    "### 멀티모달 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c9b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from google import genai\n",
    "\n",
    "# client = genai.Client()\n",
    "\n",
    "# image = Image.open(\"organ.jpg\")\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     contents=[image, \"Tell me about this instrument\"]\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b8bdd",
   "metadata": {},
   "source": [
    "위의 코드는 에러가 발생된다. 다음 페이지의 코드를 참조하기 바람 <br>\n",
    "https://ai.google.dev/gemini-api/docs/image-understanding?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 응답 ===\n",
      "제공된 이미지는 웅장하고 전통적인 **파이프 오르간의 콘솔** 부분을 보여줍니다. 여러 장의 확대된 이미지를 통해 이 악기의 세부적인 특징을 더 잘 파악할 수 있습니다.\n",
      "\n",
      "이 악기에 대해 설명해 드리겠습니다.\n",
      "\n",
      "1.  **제조사 및 설계자**: 건반 부분에 부착된 명판에 \"Skinner Organ Company\"와 \"Designed by Marshall S. Gurlman San Francisco, Cal.\"이라는 문구가 명확하게 보입니다. 이는 이 오르간이 미국의 유명한 오르간 제조사인 **스캐너 오르간 컴퍼니(Skinner Organ Company)**에서 제작되었으며, **마셜 S. 걸먼(Marshall S. Gurlman)**에 의해 설계되었음을 알려줍니다. 스캐너 오르간은 20세기 초중반에 특히 고품질의 교회 및 콘서트 오르간으로 명성을 얻었습니다.\n",
      "\n",
      "2.  **규모 및 복잡성**:\n",
      "    *   **4단 수동 건반 (Manuals)**: 연주자가 손으로 연주하는 네 개의 건반이 있습니다. 이는 매우 큰 규모의 오르간임을 나타냅니다.\n",
      "    *   **스톱 노브 (Stop Knobs)**: 콘솔 양쪽에 수많은 흰색 스톱 노브들이 배열되어 있습니다. 각 노브에는 오르간 파이프의 종류(음색)와 피치(음높이)가 적혀 있습니다. \"PEDAL\", \"SWELL\", \"CHOIR\", \"GREAT\", \"SOLO\", \"ECHO\" 등 다양한 디비전(Division)들이 존재하여 매우 풍부하고 다양한 음색을 조합할 수 있습니다.\n",
      "    *   **페달 건반 (Pedalboard)**: 하단에 발로 연주하는 페달 건반이 있습니다 (이미지 하단부에 일부만 보임).\n",
      "    *   **익스프레션 페달 (Expression Pedals)**: 발로 조작하는 세 개의 큰 페달이 보이며, 이는 각 디비전의 볼륨이나 음색 변화를 조절하는 데 사용됩니다.\n",
      "    *   **피스톤 시스템 (Piston System)**: 건반 위에 위치한 일련의 버튼들(피스톤)과 발로 조작하는 발가락 피스톤(Toe Pistons)은 미리 설정된 스톱 조합(레지스트레이션)을 한 번에 불러올 수 있게 해주는 현대적인 조합 장치입니다. 디지털 디스플레이와 \"MEMORY\", \"PREV\", \"NEXT\" 버튼이 있어 다양한 조합을 저장하고 불러올 수 있습니다.\n",
      "\n",
      "3.  **음색 다양성 (스톱 이름에서 유추)**:\n",
      "    *   **기본 음색**: \"FLUTE(플루트)\", \"DIAPASON(다이아파손)\", \"BOURDON(부르동)\" 등 오르간의 기본 음색을 제공합니다.\n",
      "    *   **현악기**: \"VIOLIN(바이올린)\", \"CELLO(첼로)\", \"VIOLA(비올라)\", \"GAMBA(감바)\" 등 현악기를 모방한 음색이 많습니다.\n",
      "    *   **리드 악기**: \"TRUMPET(트럼펫)\", \"CLARION(클라리온)\", \"OBOE(오보에)\", \"HORN(혼)\", \"TUBA(튜바)\", \"VOX HUMANA(복스 후마나)\" 등 다양한 관악기 음색을 낼 수 있습니다.\n",
      "    *   **혼합/특수 음색**: \"MIXTURE(믹스처)\", \"CELESTE(첼레스트)\" (약간 미세하게 음정이 다른 두 파이프가 내는 떨리는 소리), \"TREMOLO(트레몰로)\" (음량을 주기적으로 변화시켜 떠는 소리) 등이 있습니다.\n",
      "    *   **타악기 섹션 ('TRAPS')**: 특히 흥미로운 부분은 \"TRAPS\"라고 명시된 섹션에 \"SNARE DRUM(스네어 드럼)\", \"BASS DRUM(베이스 드럼)\", \"CRASH CYMBAL(크래쉬 심벌)\", \"TRIANGLE(트라이앵글)\", \"CHIMES(차임)\", \"HARP(하프)\", \"GONG(징)\" 등 다양한 타악기 스톱들이 있다는 것입니다. 이는 이 오르간이 일반적인 교회/콘서트 오르간을 넘어 **극장 오르간(Theatre Organ)**의 특징도 일부 갖추고 있거나, 매우 다양한 음악 장르를 소화할 수 있도록 설계되었음을 시사합니다.\n",
      "    *   **'ECHO' 디비전**: \"ECHO\"라고 명시된 스톱들은 오르간의 본체와 멀리 떨어진 위치에 파이프가 설치되어 울림이 길고 공간감 있는 소리(잔향 효과)를 내도록 설계되었음을 의미합니다.\n",
      "\n",
      "4.  **미학적 특징**: 콘솔은 고급스러운 광택이 나는 목재로 제작되었으며, 특히 하단의 지지대에는 정교한 조각이 되어 있어 뛰어난 장인 정신과 클래식한 디자인이 돋보입니다.\n",
      "\n",
      "요약하자면, 이 이미지는 Skinner Organ Company가 제작하고 Marshall S. Gurlman이 설계한 **4단 수동 건반과 페달 건반을 갖춘 웅장하고 기능적으로 매우 복잡한 파이프 오르간의 콘솔**입니다. 다양한 파이프 디비전, 수많은 음색 스톱, 현대적인 조합 장치, 그리고 특히 타악기 섹션의 포함으로 보아 매우 폭넓은 음악적 표현이 가능한 최상급 악기임을 알 수 있습니다.\n",
      "\n",
      "=== 토큰 사용량 ===\n",
      "입력 토큰: 266\n",
      "출력 토큰: 1236\n",
      "생각 토큰: 2197\n",
      "총 토큰: 3699\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# 이미지 파일을 읽어와서 바이너리 데이터로 변환\n",
    "with open(\"organ.jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        # 바이너리 타입의 이미지\n",
    "        types.Part.from_bytes(\n",
    "            # 바이너리로 읽은 데이터를 첨부하기\n",
    "            data=image_bytes,\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        # text 타입의 프로젝트\n",
    "        \"이 악기에 대해 설명해줘\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== 응답 ===\")\n",
    "print(response.text)\n",
    "print(\"\\n=== 토큰 사용량 ===\")\n",
    "print(f\"입력 토큰: {response.usage_metadata.prompt_token_count}\")\n",
    "print(f\"생각 토큰: {response.usage_metadata.thoughts_token_count}\")\n",
    "print(f\"출력 토큰: {response.usage_metadata.candidates_token_count}\")\n",
    "print(f\"총 토큰: {response.usage_metadata.total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6975309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 악기는 **오르간(Organ)**입니다. 특히, 파이프 오르간의 연주자용 콘솔(Console) 부분을 보여줍니다. 오르간은 건반 악기이자 동시에 관악기의 원리를 사용하는 독특한 악기입니다. '악기의 제왕'이라 불릴 만큼 웅장하고 풍부한 소리를 자랑합니다.\n",
      "\n",
      "**주요 특징 및 구성 요소:**\n",
      "\n",
      "1.  **수동 건반 (Manuals):**\n",
      "    *   사진 중앙에 여러 단(일반적으로 2단에서 5단 이상)으로 쌓여 있는 것이 손으로 연주하는 건반입니다. 각 건반은 특정 음색 그룹(오르간 악보에서는 '디비전'이라고도 함)을 담당합니다.\n",
      "    *   사진에는 두 단의 수동 건반이 명확히 보입니다.\n",
      "\n",
      "2.  **페달 건반 (Pedalboard):**\n",
      "    *   하단에 발로 연주하는 거대한 건반입니다. 주로 저음부를 담당하며, 오르간 연주의 특징 중 하나인 손과 발의 독립적인 사용을 가능하게 합니다.\n",
      "\n",
      "3.  **스톱 (Stops):**\n",
      "    *   건반 양쪽에 있는 수많은 버튼이나 손잡이들이 '스톱'입니다. 이 스톱을 조작하여 파이프 오르간의 다양한 음색(예: 플루트 소리, 트럼펫 소리, 현악기 소리 등)을 선택하고 조합할 수 있습니다. 각 스톱은 특정 음고(Pitch, 예: 8', 4', 2' 등)를 가진 파이프 세트를 활성화시킵니다.\n",
      "\n",
      "4.  **표현 페달 (Expression Pedals / Swell Pedals):**\n",
      "    *   페달 건반 위쪽 중앙에 발로 조작하는 페달들이 보입니다. 이 페달들은 소리의 크기(음량)를 조절하는 역할을 합니다.\n",
      "\n",
      "**작동 원리 (파이프 오르간 기준):**\n",
      "오르간은 건반과 스톱을 조작하면 파이프를 통해 공기가 흘러나와 소리를 냅니다. 수백 개에서 수만 개에 이르는 다양한 크기, 모양, 재질의 파이프들이 각각 다른 음색과 음높이를 만들어냅니다. 스톱은 이 파이프들 중 어떤 그룹을 사용할지 선택하는 역할을 합니다.\n",
      "\n",
      "**소리의 특징 및 용도:**\n",
      "오르간은 작은 속삭임 같은 소리부터 건물 전체를 울리는 웅장하고 강력한 소리까지 매우 넓은 다이내믹 레인지를 가지고 있습니다. 주로 교회나 성당에서 종교 음악 연주에 사용되며, 콘서트홀에서는 클래식 음악, 심지어 극장에서는 무성 영화 반주용(극장 오르간)으로도 사용되었습니다.\n",
      "\n",
      "이 악기는 손과 발의 고도의 협응력을 요구하는 복잡하고 매력적인 악기입니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "image = Image.open(\"organ.jpg\")\n",
    "\n",
    "# Convert image to bytes\n",
    "img_byte_arr = io.BytesIO()\n",
    "image.save(img_byte_arr, format=\"JPEG\")\n",
    "img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=\"이 악기에 대해 설명해줘\"),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(mime_type=\"image/jpeg\", data=img_byte_arr)\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347d94e",
   "metadata": {},
   "source": [
    "### 스트리밍 응답\n",
    "\n",
    "더 원활한 상호작용을 위해 스트리밍을 사용하여 GenerateContentResponse 인스턴스를 생성되는 대로 **점진적으로 수신**하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "456498c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능(AI)은 컴퓨터 시스템이 인간의 지능을 모방하여 사고하고 학습하며 문제를 해결하도록 설계된 기술입니다. 그 목표는 인간처럼 데이터를 분석하고, 추론하며, 의사결정을 내릴 수 있는 능력을 부여하는 것입니다. AI는 주로 방대한 데이터를 학습하여 숨겨진 패턴을 발견하고 예측 모델을 구축합니다. 이를 통해 명시적으로 프로그래밍되지 않은 작업도 스스로 수행하거나 개선할 수 있습니다.\n",
      "\n",
      "머신러닝, 딥러닝과 같은 하위 분야가 있으며, 이는 AI의 핵심 동력원입니다. 이미지 인식, 자연어 처리, 음성 인식 등 다양한 분야에서 뛰어난 성능을 보입니다. 현재 우리가 접하는 대부분의 AI는 특정 작업을 잘하는 '약한 인공지능'에 해당합니다.\n",
      "\n",
      "스마트폰 비서, 추천 시스템, 자율주행차 등이 일상생활 속 대표적인 AI 적용 사례입니다. AI는 효율성을 증대시키고, 복잡한 문제를 해결하며, 새로운 가치를 창출하는 데 기여합니다. 앞으로 AI는 더욱 발전하여 의료, 교육, 산업 등 사회 전반에 걸쳐 혁신을 이끌 것으로 기대됩니다."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.5-flash\", contents=[\"인공지능에 대해 2문장으로 설명해줘\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d85fd3",
   "metadata": {},
   "source": [
    "### 멀티턴 대화 (채팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5e0ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 마리나 있으시다니 정말 좋으시겠어요! 얼마나 귀여울까요? 😍\n",
      "\n",
      "어떤 종류의 강아지들인가요? 이름도 궁금하네요!\n",
      "강아지는 보통 발이 4개니까, 두 마리라면 **총 8개의 발**이 있겠네요! 😊\n",
      "role - user: 나는 우리 집에 2마리 강아지가 있다.\n",
      "role - model: 두 마리나 있으시다니 정말 좋으시겠어요! 얼마나 귀여울까요? 😍\n",
      "\n",
      "어떤 종류의 강아지들인가요? 이름도 궁금하네요!\n",
      "role - user: 그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?\n",
      "role - model: 강아지는 보통 발이 4개니까, 두 마리라면 **총 8개의 발**이 있겠네요! 😊\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
    "\n",
    "response = chat.send_message(\"나는 우리 집에 2마리 강아지가 있다.\")\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?\"\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f\"role - {message.role}\", end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec678fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='나는 우리 집에 2마리 강아지가 있다.'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text=\"\"\"와, 강아지 두 마리나 키우시는군요! 정말 좋으시겠어요. 😊\n",
       " 집안이 북적북적하고 활기 넘치겠네요!\n",
       " \n",
       " 혹시 어떤 견종인지, 이름은 무엇인지 궁금하네요! 강아지들과 함께하는 시간은 정말 소중하죠.\"\"\"\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " ),\n",
       " UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text=\"\"\"우리 집에 있는 강아지는 2마리이고, 강아지 한 마리당 발이 4개씩이니까,\n",
       " \n",
       " 총 **8개**의 발이 있습니다! 😊\"\"\"\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " )]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931967d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "without",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
